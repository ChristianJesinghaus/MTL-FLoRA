# Parameter combinations for TinyLlama mLoRA training.
# Each line (excluding comments and blank lines) has the form:
#   strat num_fl_rounds num_B epochs
#
# strat: 'centralized' or 'federated'
# num_fl_rounds: number of federated learning rounds (ignored for centralized)
# num_B: number of B matrices in the mLoRA adapter
# epochs: number of training epochs

## Centralized experiments
centralized 1 3 1
centralized 1 3 2
centralized 1 3 3
centralized 1 2 1
centralized 1 2 2
centralized 1 2 3

## Federated experiments
federated 1 3 1
federated 1 3 2
federated 1 3 3
federated 1 2 1
federated 1 2 2
federated 1 2 3
federated 2 3 1
federated 2 3 2
federated 2 3 3
federated 2 2 1
federated 2 2 2
federated 2 2 3
federated 3 3 1
federated 3 3 2
federated 3 3 3
federated 3 2 1
federated 3 2 2
federated 3 2 3